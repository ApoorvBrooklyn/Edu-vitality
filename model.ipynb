{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKHL0Lenup0ssYmYHXKHiG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ApoorvBrooklyn/Edu-vitality/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Define the number of samples per learning type\n",
        "num_samples = 10000\n",
        "\n",
        "# Simulate data for different learning types\n",
        "def generate_data(num_samples, mean_times, mean_accuracies, label):\n",
        "    response_times_audio = np.random.normal(loc=mean_times[0], scale=2, size=num_samples)\n",
        "    response_times_picture = np.random.normal(loc=mean_times[1], scale=2, size=num_samples)\n",
        "    response_times_paragraph = np.random.normal(loc=mean_times[2], scale=2, size=num_samples)\n",
        "\n",
        "    accuracies_audio = np.random.normal(loc=mean_accuracies[0], scale=0.1, size=num_samples)\n",
        "    accuracies_picture = np.random.normal(loc=mean_accuracies[1], scale=0.1, size=num_samples)\n",
        "    accuracies_paragraph = np.random.normal(loc=mean_accuracies[2], scale=0.1, size=num_samples)\n",
        "\n",
        "    labels = [label] * num_samples\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'response_time_audio': response_times_audio,\n",
        "        'response_time_picture': response_times_picture,\n",
        "        'response_time_paragraph': response_times_paragraph,\n",
        "        'accuracy_audio': accuracies_audio,\n",
        "        'accuracy_picture': accuracies_picture,\n",
        "        'accuracy_paragraph': accuracies_paragraph,\n",
        "        'label': labels\n",
        "    })\n",
        "\n",
        "# Generate data for each type of learner\n",
        "kinesthetic = generate_data(num_samples, mean_times=[8, 10, 12], mean_accuracies=[0.8, 0.7, 0.6], label='Kinesthetic Learner')\n",
        "auditory = generate_data(num_samples, mean_times=[15, 17, 20], mean_accuracies=[0.7, 0.6, 0.8], label='Auditory Learner')\n",
        "visual = generate_data(num_samples, mean_times=[20, 18, 22], mean_accuracies=[0.9, 0.85, 0.9], label='Visual Learner')\n",
        "reading_writing = generate_data(num_samples, mean_times=[10, 15, 8], mean_accuracies=[0.7, 0.75, 0.8], label='Reading/Writing Learner')\n",
        "logical = generate_data(num_samples, mean_times=[12, 18, 15], mean_accuracies=[0.85, 0.8, 0.9], label='Logical Learner')\n",
        "social = generate_data(num_samples, mean_times=[18, 12, 15], mean_accuracies=[0.6, 0.7, 0.65], label='Social Learner')\n",
        "solitary = generate_data(num_samples, mean_times=[22, 20, 25], mean_accuracies=[0.75, 0.7, 0.8], label='Solitary Learner')\n",
        "\n",
        "# Combine the data into a single DataFrame\n",
        "data = pd.concat([kinesthetic, auditory, visual, reading_writing, logical, social, solitary], ignore_index=True)\n",
        "\n",
        "# Shuffle the dataset\n",
        "data = data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Save dataset to a CSV file for use in training\n",
        "data.to_csv('learning_preferences.csv', index=False)"
      ],
      "metadata": {
        "id": "28ZC_tVvnbx2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JsbInLLUn3Gz",
        "outputId": "1c1758d5-d322-41b5-f7e0-8af131986488"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   response_time_audio  response_time_picture  response_time_paragraph  \\\n",
              "0            20.950447              15.187713                22.315704   \n",
              "1             4.833850               8.398520                10.821124   \n",
              "2            13.764116              18.056675                18.736389   \n",
              "3            18.481643              16.984392                23.504387   \n",
              "4            13.242961              16.299147                 6.678983   \n",
              "\n",
              "   accuracy_audio  accuracy_picture  accuracy_paragraph  \\\n",
              "0        0.762316          0.860158            0.865855   \n",
              "1        0.726826          0.717105            0.675186   \n",
              "2        0.555639          0.612328            0.793344   \n",
              "3        0.774959          0.700815            0.702778   \n",
              "4        0.664808          0.877323            0.814933   \n",
              "\n",
              "                     label  \n",
              "0           Visual Learner  \n",
              "1      Kinesthetic Learner  \n",
              "2         Auditory Learner  \n",
              "3         Solitary Learner  \n",
              "4  Reading/Writing Learner  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-effd12b7-c4c9-48b9-913f-31546f8c9912\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response_time_audio</th>\n",
              "      <th>response_time_picture</th>\n",
              "      <th>response_time_paragraph</th>\n",
              "      <th>accuracy_audio</th>\n",
              "      <th>accuracy_picture</th>\n",
              "      <th>accuracy_paragraph</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.950447</td>\n",
              "      <td>15.187713</td>\n",
              "      <td>22.315704</td>\n",
              "      <td>0.762316</td>\n",
              "      <td>0.860158</td>\n",
              "      <td>0.865855</td>\n",
              "      <td>Visual Learner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.833850</td>\n",
              "      <td>8.398520</td>\n",
              "      <td>10.821124</td>\n",
              "      <td>0.726826</td>\n",
              "      <td>0.717105</td>\n",
              "      <td>0.675186</td>\n",
              "      <td>Kinesthetic Learner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.764116</td>\n",
              "      <td>18.056675</td>\n",
              "      <td>18.736389</td>\n",
              "      <td>0.555639</td>\n",
              "      <td>0.612328</td>\n",
              "      <td>0.793344</td>\n",
              "      <td>Auditory Learner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18.481643</td>\n",
              "      <td>16.984392</td>\n",
              "      <td>23.504387</td>\n",
              "      <td>0.774959</td>\n",
              "      <td>0.700815</td>\n",
              "      <td>0.702778</td>\n",
              "      <td>Solitary Learner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.242961</td>\n",
              "      <td>16.299147</td>\n",
              "      <td>6.678983</td>\n",
              "      <td>0.664808</td>\n",
              "      <td>0.877323</td>\n",
              "      <td>0.814933</td>\n",
              "      <td>Reading/Writing Learner</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-effd12b7-c4c9-48b9-913f-31546f8c9912')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-effd12b7-c4c9-48b9-913f-31546f8c9912 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-effd12b7-c4c9-48b9-913f-31546f8c9912');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-98eeccfb-9125-48be-8f6e-9c8d01b03565\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-98eeccfb-9125-48be-8f6e-9c8d01b03565')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-98eeccfb-9125-48be-8f6e-9c8d01b03565 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 70000,\n  \"fields\": [\n    {\n      \"column\": \"response_time_audio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.254574243448998,\n        \"min\": 0.7058093749636329,\n        \"max\": 30.085940056195188,\n        \"num_unique_values\": 70000,\n        \"samples\": [\n          21.812306584050997,\n          16.439339064439267,\n          14.754207736057573\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_time_picture\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.8879638265171144,\n        \"min\": 2.685728525953805,\n        \"max\": 28.092783713693805,\n        \"num_unique_values\": 70000,\n        \"samples\": [\n          19.033622347934145,\n          16.70602546214164,\n          14.437236743434696\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_time_paragraph\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.850399490722919,\n        \"min\": -1.1675935300789675,\n        \"max\": 31.937379932761043,\n        \"num_unique_values\": 70000,\n        \"samples\": [\n          22.878932296852454,\n          22.246994745522443,\n          24.2667241735786\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy_audio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13721860864235344,\n        \"min\": 0.16700449950681695,\n        \"max\": 1.2699858989332704,\n        \"num_unique_values\": 70000,\n        \"samples\": [\n          0.9187555447260163,\n          0.6616523543240428,\n          0.6055618819974791\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy_picture\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12466562875135295,\n        \"min\": 0.25713284130744773,\n        \"max\": 1.2492815948155895,\n        \"num_unique_values\": 70000,\n        \"samples\": [\n          0.9119103114915491,\n          0.5617620417012115,\n          0.7219049901631829\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy_paragraph\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14610991758858097,\n        \"min\": 0.22835072883485935,\n        \"max\": 1.2884310031056407,\n        \"num_unique_values\": 70000,\n        \"samples\": [\n          0.8133502718303827,\n          0.8959508675679084,\n          0.6826557191883094\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Visual Learner\",\n          \"Kinesthetic Learner\",\n          \"Social Learner\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('learning_preferences.csv')\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "data['label'] = label_encoder.fit_transform(data['label'])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X = data.drop(columns=['label'])\n",
        "y = data['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape data for LSTM layer\n",
        "X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# Define the RNN model using LSTM\n",
        "model = Sequential([\n",
        "    LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(len(label_encoder.classes_), activation='softmax')  # Output classes for the 7 learning types\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Save the trained model\n",
        "model.save('learning_preference_model_rnn.h5')\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xKk22h5spZ7W",
        "outputId": "1e6107d1-b5cc-484b-9cb0-869662ce7ae0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1750/1750 [==============================] - 7s 3ms/step - loss: 0.4061 - accuracy: 0.8465 - val_loss: 0.2270 - val_accuracy: 0.9159\n",
            "Epoch 2/50\n",
            "1750/1750 [==============================] - 4s 2ms/step - loss: 0.1971 - accuracy: 0.9260 - val_loss: 0.1640 - val_accuracy: 0.9391\n",
            "Epoch 3/50\n",
            "1750/1750 [==============================] - 5s 3ms/step - loss: 0.1723 - accuracy: 0.9358 - val_loss: 0.1522 - val_accuracy: 0.9445\n",
            "Epoch 4/50\n",
            "1750/1750 [==============================] - 5s 3ms/step - loss: 0.1617 - accuracy: 0.9393 - val_loss: 0.1536 - val_accuracy: 0.9425\n",
            "Epoch 5/50\n",
            "1750/1750 [==============================] - 4s 3ms/step - loss: 0.1580 - accuracy: 0.9419 - val_loss: 0.1465 - val_accuracy: 0.9467\n",
            "Epoch 6/50\n",
            "1750/1750 [==============================] - 6s 3ms/step - loss: 0.1514 - accuracy: 0.9435 - val_loss: 0.1724 - val_accuracy: 0.9367\n",
            "Epoch 7/50\n",
            "1750/1750 [==============================] - 4s 2ms/step - loss: 0.1490 - accuracy: 0.9451 - val_loss: 0.1436 - val_accuracy: 0.9469\n",
            "Epoch 8/50\n",
            "1750/1750 [==============================] - 4s 3ms/step - loss: 0.1465 - accuracy: 0.9448 - val_loss: 0.1370 - val_accuracy: 0.9488\n",
            "Epoch 9/50\n",
            "1750/1750 [==============================] - 6s 3ms/step - loss: 0.1432 - accuracy: 0.9467 - val_loss: 0.1418 - val_accuracy: 0.9481\n",
            "Epoch 10/50\n",
            "1750/1750 [==============================] - 4s 3ms/step - loss: 0.1439 - accuracy: 0.9460 - val_loss: 0.1597 - val_accuracy: 0.9407\n",
            "Epoch 11/50\n",
            "1750/1750 [==============================] - 6s 3ms/step - loss: 0.1416 - accuracy: 0.9468 - val_loss: 0.1361 - val_accuracy: 0.9514\n",
            "Epoch 12/50\n",
            "1750/1750 [==============================] - 5s 3ms/step - loss: 0.1417 - accuracy: 0.9468 - val_loss: 0.1368 - val_accuracy: 0.9483\n",
            "Epoch 13/50\n",
            "1750/1750 [==============================] - 4s 3ms/step - loss: 0.1415 - accuracy: 0.9473 - val_loss: 0.1604 - val_accuracy: 0.9406\n",
            "Epoch 14/50\n",
            "1750/1750 [==============================] - 6s 3ms/step - loss: 0.1422 - accuracy: 0.9467 - val_loss: 0.1425 - val_accuracy: 0.9472\n",
            "Epoch 15/50\n",
            "1750/1750 [==============================] - 4s 3ms/step - loss: 0.1383 - accuracy: 0.9487 - val_loss: 0.1367 - val_accuracy: 0.9500\n",
            "Epoch 16/50\n",
            "1750/1750 [==============================] - 5s 3ms/step - loss: 0.1401 - accuracy: 0.9479 - val_loss: 0.1393 - val_accuracy: 0.9490\n",
            "Epoch 17/50\n",
            "1750/1750 [==============================] - 6s 3ms/step - loss: 0.1394 - accuracy: 0.9482 - val_loss: 0.1388 - val_accuracy: 0.9484\n",
            "Epoch 18/50\n",
            "1750/1750 [==============================] - 5s 3ms/step - loss: 0.1386 - accuracy: 0.9483 - val_loss: 0.1483 - val_accuracy: 0.9459\n",
            "Epoch 19/50\n",
            "1750/1750 [==============================] - 5s 3ms/step - loss: 0.1387 - accuracy: 0.9483 - val_loss: 0.1376 - val_accuracy: 0.9492\n",
            "Epoch 20/50\n",
            "1750/1750 [==============================] - 6s 3ms/step - loss: 0.1389 - accuracy: 0.9484 - val_loss: 0.1500 - val_accuracy: 0.9439\n",
            "Epoch 21/50\n",
            "1750/1750 [==============================] - 4s 3ms/step - loss: 0.1383 - accuracy: 0.9477 - val_loss: 0.1405 - val_accuracy: 0.9481\n",
            "Epoch 22/50\n",
            "1750/1750 [==============================] - 5s 3ms/step - loss: 0.1356 - accuracy: 0.9498 - val_loss: 0.1347 - val_accuracy: 0.9505\n",
            "Epoch 23/50\n",
            "1750/1750 [==============================] - 5s 3ms/step - loss: 0.1361 - accuracy: 0.9493 - val_loss: 0.1529 - val_accuracy: 0.9441\n",
            "Epoch 24/50\n",
            "1750/1750 [==============================] - 4s 3ms/step - loss: 0.1349 - accuracy: 0.9497 - val_loss: 0.1443 - val_accuracy: 0.9466\n",
            "Epoch 25/50\n",
            "1750/1750 [==============================] - 6s 3ms/step - loss: 0.1366 - accuracy: 0.9492 - val_loss: 0.1413 - val_accuracy: 0.9474\n",
            "Epoch 26/50\n",
            "1750/1750 [==============================] - 4s 3ms/step - loss: 0.1353 - accuracy: 0.9498 - val_loss: 0.1460 - val_accuracy: 0.9456\n",
            "Epoch 27/50\n",
            "1750/1750 [==============================] - 5s 3ms/step - loss: 0.1367 - accuracy: 0.9484 - val_loss: 0.1363 - val_accuracy: 0.9504\n",
            "Epoch 28/50\n",
            "1750/1750 [==============================] - 6s 3ms/step - loss: 0.1353 - accuracy: 0.9491 - val_loss: 0.1619 - val_accuracy: 0.9419\n",
            "Epoch 29/50\n",
            "1750/1750 [==============================] - 5s 3ms/step - loss: 0.1345 - accuracy: 0.9503 - val_loss: 0.1328 - val_accuracy: 0.9523\n",
            "Epoch 30/50\n",
            "1750/1750 [==============================] - 5s 3ms/step - loss: 0.1344 - accuracy: 0.9497 - val_loss: 0.1539 - val_accuracy: 0.9435\n",
            "Epoch 31/50\n",
            "1750/1750 [==============================] - 5s 3ms/step - loss: 0.1345 - accuracy: 0.9496 - val_loss: 0.1522 - val_accuracy: 0.9448\n",
            "Epoch 32/50\n",
            "1750/1750 [==============================] - 5s 3ms/step - loss: 0.1329 - accuracy: 0.9505 - val_loss: 0.1313 - val_accuracy: 0.9525\n",
            "Epoch 33/50\n",
            "1750/1750 [==============================] - 6s 3ms/step - loss: 0.1365 - accuracy: 0.9483 - val_loss: 0.1477 - val_accuracy: 0.9450\n",
            "Epoch 34/50\n",
            "1750/1750 [==============================] - 4s 3ms/step - loss: 0.1329 - accuracy: 0.9497 - val_loss: 0.1771 - val_accuracy: 0.9362\n",
            "Epoch 35/50\n",
            "1750/1750 [==============================] - 4s 3ms/step - loss: 0.1352 - accuracy: 0.9500 - val_loss: 0.1819 - val_accuracy: 0.9336\n",
            "Epoch 36/50\n",
            "1750/1750 [==============================] - 6s 3ms/step - loss: 0.1339 - accuracy: 0.9498 - val_loss: 0.1556 - val_accuracy: 0.9451\n",
            "Epoch 37/50\n",
            "1750/1750 [==============================] - 4s 3ms/step - loss: 0.1329 - accuracy: 0.9506 - val_loss: 0.1367 - val_accuracy: 0.9496\n",
            "Epoch 38/50\n",
            "1750/1750 [==============================] - 5s 3ms/step - loss: 0.1341 - accuracy: 0.9494 - val_loss: 0.1430 - val_accuracy: 0.9490\n",
            "Epoch 39/50\n",
            "1750/1750 [==============================] - 5s 3ms/step - loss: 0.1345 - accuracy: 0.9496 - val_loss: 0.1387 - val_accuracy: 0.9486\n",
            "Epoch 40/50\n",
            "1750/1750 [==============================] - 4s 3ms/step - loss: 0.1337 - accuracy: 0.9501 - val_loss: 0.1383 - val_accuracy: 0.9504\n",
            "Epoch 41/50\n",
            "1750/1750 [==============================] - 6s 3ms/step - loss: 0.1338 - accuracy: 0.9499 - val_loss: 0.1416 - val_accuracy: 0.9479\n",
            "Epoch 42/50\n",
            "1750/1750 [==============================] - 5s 3ms/step - loss: 0.1328 - accuracy: 0.9495 - val_loss: 0.1341 - val_accuracy: 0.9501\n",
            "Epoch 43/50\n",
            "1750/1750 [==============================] - 4s 3ms/step - loss: 0.1321 - accuracy: 0.9507 - val_loss: 0.1330 - val_accuracy: 0.9515\n",
            "Epoch 44/50\n",
            "1750/1750 [==============================] - 6s 3ms/step - loss: 0.1341 - accuracy: 0.9503 - val_loss: 0.1349 - val_accuracy: 0.9506\n",
            "Epoch 45/50\n",
            "1750/1750 [==============================] - 4s 3ms/step - loss: 0.1334 - accuracy: 0.9504 - val_loss: 0.1358 - val_accuracy: 0.9488\n",
            "Epoch 46/50\n",
            "1750/1750 [==============================] - 4s 3ms/step - loss: 0.1327 - accuracy: 0.9501 - val_loss: 0.1447 - val_accuracy: 0.9456\n",
            "Epoch 47/50\n",
            "1750/1750 [==============================] - 6s 3ms/step - loss: 0.1327 - accuracy: 0.9508 - val_loss: 0.1555 - val_accuracy: 0.9443\n",
            "Epoch 48/50\n",
            "1750/1750 [==============================] - 4s 3ms/step - loss: 0.1311 - accuracy: 0.9507 - val_loss: 0.1379 - val_accuracy: 0.9495\n",
            "Epoch 49/50\n",
            "1750/1750 [==============================] - 5s 3ms/step - loss: 0.1322 - accuracy: 0.9507 - val_loss: 0.1365 - val_accuracy: 0.9496\n",
            "Epoch 50/50\n",
            "1750/1750 [==============================] - 6s 4ms/step - loss: 0.1332 - accuracy: 0.9501 - val_loss: 0.1367 - val_accuracy: 0.9509\n",
            " 33/438 [=>............................] - ETA: 0s - loss: 0.1618 - accuracy: 0.9394"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "438/438 [==============================] - 1s 2ms/step - loss: 0.1367 - accuracy: 0.9509\n",
            "Test Accuracy: 95.09%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iQzucNGr2Bs",
        "outputId": "029b3c99-77eb-4222-fa37-269169126e37"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.35.0-py2.py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.0)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.1)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.6.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.35.0 watchdog-4.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('learning_preference_model_rnn.h5')\n",
        "\n",
        "# Define the label encoder for decoding the predicted labels\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.classes_ = np.array(['Auditory Learner', 'Kinesthetic Learner', 'Logical Learner', 'Reading/Writing Learner', 'Social Learner', 'Solitary Learner', 'Visual Learner'])\n",
        "\n",
        "st.title(\"üìì QUIZ\")\n",
        "st.subheader(\"Questions\")\n",
        "\n",
        "# Define multiple sets of questions with correct answers\n",
        "question_sets = [\n",
        "    [\n",
        "        {\"type\": \"audio\", \"question\": \"Listen to the audio and choose the correct answer for question 1.1\", \"options\": [\"Option 1.1.1\", \"Option 1.1.2\", \"Option 1.1.3\"], \"answer\": \"Option 1.1.2\", \"media\": \"https://www.soundhelix.com/examples/mp3/SoundHelix-Song-1.mp3\"},\n",
        "        {\"type\": \"picture\", \"question\": \"Look at the picture and choose the correct answer for question 1.2\", \"options\": [\"Option 1.2.1\", \"Option 1.2.2\", \"Option 1.2.3\"], \"answer\": \"Option 1.2.1\", \"media\": \"https://via.placeholder.com/150\"},\n",
        "        {\"type\": \"paragraph\", \"question\": \"Read the paragraph and choose the correct answer for question 1.3\", \"options\": [\"Option 1.3.1\", \"Option 1.3.2\", \"Option 1.3.3\"], \"answer\": \"Option 1.3.3\", \"media\": \"This is a sample paragraph for question 1.3.\"}\n",
        "    ],\n",
        "    [\n",
        "        {\"type\": \"audio\", \"question\": \"Listen to the audio and choose the correct answer for question 2.1\", \"options\": [\"Option 2.1.1\", \"Option 2.1.2\", \"Option 2.1.3\"], \"answer\": \"Option 2.1.3\", \"media\": \"https://www.soundhelix.com/examples/mp3/SoundHelix-Song-1.mp3\"},\n",
        "        {\"type\": \"picture\", \"question\": \"Look at the picture and choose the correct answer for question 2.2\", \"options\": [\"Option 2.2.1\", \"Option 2.2.2\", \"Option 2.2.3\"], \"answer\": \"Option 2.2.2\", \"media\": \"https://via.placeholder.com/150\"},\n",
        "        {\"type\": \"paragraph\", \"question\": \"Read the paragraph and choose the correct answer for question 2.3\", \"options\": [\"Option 2.3.1\", \"Option 2.3.2\", \"Option 2.3.3\"], \"answer\": \"Option 2.3.1\", \"media\": \"This is a sample paragraph for question 2.3.\"}\n",
        "    ]\n",
        "]\n",
        "\n",
        "# Initialize session state to keep track of the current question set, start time, and individual times\n",
        "if 'current_question_set' not in st.session_state:\n",
        "    st.session_state.current_question_set = 0\n",
        "    st.session_state.start_time = time.time()\n",
        "    st.session_state.question_times = []\n",
        "\n",
        "# Get the current set of questions\n",
        "questions = question_sets[st.session_state.current_question_set]\n",
        "\n",
        "# Create a form for the quiz\n",
        "form = st.form(key=\"quiz_form\")\n",
        "\n",
        "# Dictionary to store the answers and response times\n",
        "answers = {}\n",
        "question_times = st.session_state.question_times\n",
        "\n",
        "# Loop through the questions and create appropriate input based on type\n",
        "for i, q in enumerate(questions):\n",
        "    if len(question_times) <= i:\n",
        "        question_times.append(time.time())\n",
        "\n",
        "    if q[\"type\"] == \"audio\":\n",
        "        form.audio(q[\"media\"])\n",
        "    elif q[\"type\"] == \"picture\":\n",
        "        form.image(q[\"media\"])\n",
        "    elif q[\"type\"] == \"paragraph\":\n",
        "        form.write(q[\"media\"])\n",
        "\n",
        "    answers[f\"q{i+1}\"] = form.radio(q[\"question\"], options=q[\"options\"])\n",
        "\n",
        "# Submit button for the form\n",
        "submitted = form.form_submit_button(\"Submit your answers\")\n",
        "\n",
        "# Display the answers and move to the next set of questions\n",
        "if submitted:\n",
        "    end_time = time.time()\n",
        "    individual_times = [end_time - t for t in question_times]\n",
        "\n",
        "    correctness_audio = sum(1 for i, q in enumerate(questions) if q[\"type\"] == \"audio\" and answers[f\"q{i+1}\"] == q[\"answer\"])\n",
        "    correctness_picture = sum(1 for i, q in enumerate(questions) if q[\"type\"] == \"picture\" and answers[f\"q{i+1}\"] == q[\"answer\"])\n",
        "    correctness_paragraph = sum(1 for i, q in enumerate(questions) if q[\"type\"] == \"paragraph\" and answers[f\"q{i+1}\"] == q[\"answer\"])\n",
        "\n",
        "    time_audio = sum(individual_times[i] for i, q in enumerate(questions) if q[\"type\"] == \"audio\")\n",
        "    time_picture = sum(individual_times[i] for i, q in enumerate(questions) if q[\"type\"] == \"picture\")\n",
        "    time_paragraph = sum(individual_times[i] for i, q in enumerate(questions) if q[\"type\"] == \"paragraph\")\n",
        "\n",
        "    input_features = np.array([[time_audio, correctness_audio, time_picture, correctness_picture, time_paragraph, correctness_paragraph]])\n",
        "\n",
        "    # Predict the learning preference\n",
        "    prediction = model.predict(input_features)\n",
        "    predicted_label = label_encoder.inverse_transform(np.argmax(prediction, axis=1))\n",
        "\n",
        "    st.write(f\"Response time for audio questions: {time_audio:.2f} seconds\")\n",
        "    st.write(f\"Correct answers for audio questions: {correctness_audio}\")\n",
        "    st.write(f\"Response time for picture questions: {time_picture:.2f} seconds\")\n",
        "    st.write(f\"Correct answers for picture questions: {correctness_picture}\")\n",
        "    st.write(f\"Response time for paragraph questions: {time_paragraph:.2f} seconds\")\n",
        "    st.write(f\"Correct answers for paragraph questions: {correctness_paragraph}\")\n",
        "    st.write(f\"Predicted learning preference: {predicted_label[0]}\")\n",
        "\n",
        "    for i, q in enumerate(questions):\n",
        "        st.write(f\"Your answer for question {i+1}: {answers[f'q{i+1}']} (Correct: {q['answer']})\")\n",
        "\n",
        "    if st.session_state.current_question_set < len(question_sets) - 1:\n",
        "        st.session_state.current_question_set += 1\n",
        "        st.session_state.start_time = time.time()  # Reset the start time for the next set\n",
        "        st.experimental_rerun()  # Rerun the app to load the next set of questions\n",
        "    else:\n",
        "        st.write(\"No more questions available.\")\n"
      ],
      "metadata": {
        "id": "pNzT-rP3skHM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('/mnt/data/learning_preference_model.h5')\n",
        "\n",
        "# Define the label encoder for decoding the predicted labels\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.classes_ = np.array(['Auditory Learner', 'Kinesthetic Learner', 'Logical Learner', 'Reading/Writing Learner', 'Social Learner', 'Solitary Learner', 'Visual Learner'])\n",
        "\n",
        "# Function to predict learning preference\n",
        "def predict_learning_preference(input_features):\n",
        "    prediction = model.predict(input_features)\n",
        "    predicted_label = label_encoder.inverse_transform(np.argmax(prediction, axis=1))\n",
        "    return predicted_label[0]\n",
        "\n",
        "# Generate sample inputs for testing the model\n",
        "sample_input_features = np.array([\n",
        "    [15, 2, 25, 1, 35, 3],  # Example 1: Different response times and correctness scores\n",
        "    [10, 3, 20, 3, 30, 2],  # Example 2: Different response times and correctness scores\n",
        "    [5, 1, 15, 1, 25, 1]    # Example 3: Different response times and correctness scores\n",
        "])\n",
        "\n",
        "# Predict and display the learning preferences for the sample inputs\n",
        "for i, sample_input in enumerate(sample_input_features):\n",
        "    predicted_preference = predict_learning_preference(sample_input.reshape(1, -1))\n",
        "    print(f\"Sample Input {i+1}: {sample_input}\")\n",
        "    print(f\"Predicted Learning Preference: {predicted_preference}\\n\")\n"
      ],
      "metadata": {
        "id": "mWoHqw06C16H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('learning_preference_model_rnn.h5')\n",
        "\n",
        "# Define the label encoder for decoding the predicted labels\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.classes_ = np.array(['Auditory Learner', 'Kinesthetic Learner', 'Logical Learner', 'Reading/Writing Learner', 'Social Learner', 'Solitary Learner', 'Visual Learner'])\n",
        "\n",
        "# Function to predict learning preference\n",
        "def predict_learning_preference(input_features):\n",
        "    input_features = input_features.reshape((input_features.shape[0], 1, input_features.shape[1]))\n",
        "    prediction = model.predict(input_features)\n",
        "    predicted_label = label_encoder.inverse_transform(np.argmax(prediction, axis=1))\n",
        "    return predicted_label[0]\n",
        "\n",
        "# Generate sample inputs for testing the model\n",
        "sample_input_features = np.array([\n",
        "    [1, 2, 2, 10, 35, 3],  # Example 1: Different response times and correctness scores\n",
        "    [10, 30, 20, 1, 3, 2],  # Example 2: Different response times and correctness scores\n",
        "    [50, 1, 1, 10, 25, 1]    # Example 3: Different response times and correctness scores\n",
        "])\n",
        "\n",
        "# Predict and display the learning preferences for the sample inputs\n",
        "for i, sample_input in enumerate(sample_input_features):\n",
        "    predicted_preference = predict_learning_preference(sample_input.reshape(1, -1))\n",
        "    print(f\"Sample Input {i+1}: {sample_input}\")\n",
        "    print(f\"Predicted Learning Preference: {predicted_preference}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPDh_KvaDSWV",
        "outputId": "a99c838c-29a1-47c5-818a-2ccda4b97ec3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 193ms/step\n",
            "Sample Input 1: [ 1  2  2 10 35  3]\n",
            "Predicted Learning Preference: Reading/Writing Learner\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Sample Input 2: [10 30 20  1  3  2]\n",
            "Predicted Learning Preference: Logical Learner\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Sample Input 3: [50  1  1 10 25  1]\n",
            "Predicted Learning Preference: Kinesthetic Learner\n",
            "\n"
          ]
        }
      ]
    }
  ]
}